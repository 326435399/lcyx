<!DOCTYPE html>
<html lang="zh-cn">
    <head>
        <meta charset="UTF-8">
        <meta name="StrawBear" content="width=device-width,initial-scale=1.0">
        <title>深度学习入门-基于Python的理论与实现</title>
        <link rel="stylesheet" href="../../../1_CSS/basicStyle.css">
    </head>   
    <body>
        <aside>
            <ul>
                <li><a href="#1">1.Python入门</a>
                    <ul>
                        <li><a href="#1.1">1.1 Python是什么</a></li>
                        <li><a href="#1.2">1.2 Python安装</a></li>
                        <li><a href="#1.3">1.3 Python解释器</a></li>
                        <li><a href="#1.4">1.4 Python脚本文件</a></li>
                        <li><a href="#1.5">1.5 NumPy</a></li>
                        <li><a href="#1.6">1.6 Matplotlib</a></li>
                        <li><a href="#1.7">1.7 小结</a></li>
                    </ul>
                </li>
                <li><a href="#2">2.感知机</a>
                    <ul>
                        <li><a href="#2.1">2.1 感知机是什么</a></li>
                        <li><a href="#2.2">2.2 简单逻辑电路</a></li>
                        <li><a href="#2.3">2.3 感知机的实现</a></li>
                        <li><a href="#2.4">2.4 感知机的局限性</a></li>
                        <li><a href="#2.5">2.5 多层感知机</a></li>
                        <li><a href="#2.6">2.6 从与非门到计算机</a></li>
                        <li><a href="#2.7">2.7 小结</a></li>
                    </ul>
                </li>
                <li><a href="#3">3.神经网络</a>
                    <ul>
                        <li><a href="#3.1">3.1 从感知机到神经网络</a></li>
                        <li><a href="#3.2">3.2 激活函数</a></li>
                        <li><a href="#3.3">3.3 多维数组的运算</a></li>
                        <li><a href="#3.4">3.4 3层神经网络的实现</a></li>
                        <li><a href="#3.5">3.5 输出层的设计</a></li>
                        <li><a href="#3.6">3.6 手写数字识别</a></li>
                        <li><a href="#3.7">3.7 小结</a></li>
                    </ul>
                </li>
                <li><a href="#4">4.神经网络的学习</a>
                    <ul>
                        <li><a href="#4.1">4.1 从数据中学习</a></li>
                        <li><a href="#4.2">4.2 损失函数</a></li>
                        <li><a href="#4.3">4.3 数值微分</a></li>
                        <li><a href="#4.4">4.4 梯度</a></li>
                        <li><a href="#4.5">4.5 学习算法的实现</a></li>
                        <li><a href="#4.6">4.6 小结</a></li>
                    </ul>
                </li>
                <li><a href="#5">5.误差反向传播法</a>
                    <ul>
                        <li><a href="#5.1">5.1 计算图</a></li>
                        <li><a href="#5.2">5.2 链式法则</a></li>
                        <li><a href="#5.3">5.3 反向传播</a></li>
                        <li><a href="#5.4">5.4 简单层的实现</a></li>
                        <li><a href="#5.5">5.5 激活函数层的实现</a></li>
                        <li><a href="#5.6">5.6 Affine/Softmax层的实现</a></li>
                        <li><a href="#5.7">5.7 误差反向传播法的实现</a></li>
                        <li><a href="#5.8">5.8 小结</a></li>
                    </ul>
                </li>
                <li><a href="#6">6.与学习相关的技巧</a>
                    <ul>
                        <li><a href="#6.1">6.1 参数的更新</a></li>
                        <li><a href="#6.2">6.2 权重的初始值</a></li>
                        <li><a href="#6.3">6.3 Batch Normalization</a></li>
                        <li><a href="#6.4">6.4 正则化</a></li>
                        <li><a href="#6.5">6.5 超参数的验证</a></li>
                        <li><a href="#6.6">6.6 小结</a></li>
                    </ul>
                </li>
                <li><a href="#7">7.卷积神经网络</a>
                    <ul>
                        <li><a href="#7.1">7.1 整体结构</a></li>
                        <li><a href="#7.2">7.2 卷积层</a></li>
                        <li><a href="#7.3">7.3 池化层</a></li>
                        <li><a href="#7.4">7.4 卷积层和池化层的实现</a></li>
                        <li><a href="#7.5">7.5 CNN的实现</a></li>
                        <li><a href="#7.6">7.6 CNN的可视化</a></li>
                        <li><a href="#7.7">7.7 具有代表性的CNN</a></li>
                        <li><a href="#7.8">7.8 小结</a></li>
                    </ul>
                </li>
                <li><a href="#8">8.深度学习</a>
                    <ul>
                        <li><a href="#8.1">8.1 加深网络</a></li>
                        <li><a href="#8.2">8.2 深度学习的小历史</a></li>
                        <li><a href="#8.3">8.3 深度学习的高速化</a></li>
                        <li><a href="#8.4">8.4 深度学习的应用案例</a></li>
                        <li><a href="#8.5">8.5 深度学习的未来</a></li>
                        <li><a href="#8.6">8.6 小结</a></li>
                    </ul>
                </li>
                <li><a href="#9">9.附录和其他</a>
                    <ul>
                        <li><a href="#9.1">9.1特殊的学习思路</a></li>
                        <li><a href="#9.2">9.2附录</a></li>
                    </ul>
                </li>

            </ul>
        </aside>
        <nav>
            <a href="#20240524"><img style="width:18pt" src="Resources/other/跳转.jpg" alt="跳转"></a>20240524:万物初开<br>
            故事背景:鱼叔的深度学习之旅--(PS:鱼叔也指代鱼书学习,鱼叔是一个理工男,厚厚的黑框眼镜,完全不了解深度学习的概念,数学基础一般,代码基础一般)<br>
            <a href="#20240527"><img style="width:18pt" src="Resources/other/跳转.jpg" alt="跳转"></a>20240527:脉络梳理<br>
            图书对全书的整体脉络进行了梳理,书籍先介绍基础的<strong>编程知识</strong>,通过<strong>感知机</strong>引出<strong>神经网络</strong>,
            先学习简单的<strong>前向传播,激活函数</strong>,再进一步学习复杂的<strong>反向传播</strong>,了解使用<strong>数值微分</strong>的方式来衡量学习是否正确,
            最后通过学习计算图<strong>可视化,批量数据,合批</strong>等等方式优化性能,最终引入了进一步的复杂的<strong>卷积神经网络CNN</strong>.
            <a href="#20240603"><img style="width:18pt" src="Resources/other/跳转.jpg" alt="跳转"></a>20240603:python认知<br>
            我们为Python提供了两个库,Numpy用来数值计算,MatPlotlib用来可视化结果,Python可以用解释器模式和脚本文件模式<br>
            <a href="#20240625"><img style="width:18pt" src="Resources/other/跳转.jpg" alt="跳转"></a>20240625:感知机和逻辑电路<br>
            了解<strong>感知机是什么</strong>,并用感知机来实现<strong>逻辑电路</strong>.<br>

        </nav>
        <header>
            <p class="header">深度学习入门-基于Python的理论与实现</p>
            <figure>
                <img src="深度学习入门-基于Python的理论与实现.jpg" alt="封面">
            </figure>
        </header>
        <article id="1"><p class="chapter">1.Python入门</p>
            <p class="timeStamp" id="20240603">20240603-python认知</p>
            <section id="1.1"><p class="section">1.1 Python是什么</p>
                <div>
                    <p>Python是一个简单,易读,易记的编程语言.<br></p>
                </div>
            </section>
            <section id="1.2"><p class="section">1.2 Python安装</p>
                <div>
                    <p>
                        Python版本:现在可以到3.x版本了,使用的3.11版本<br>
                        使用的外部库:Numpy是用于数值计算的库,来进行数学操作,Matplotlib是用来画图的库,来将结果可视化.<br>
                        Anaconda发行版包:是针对数据计算领域的python合集,包含常用的Numpy,Matplotlib等库的集合<br>
                    </p>
                </div>
            </section>
            <section id="1.3"><p class="section">1.3 Python解释器</p>
                <div>
                    <p>
                        可以使用type()来查看数据类型,python的数据类型是动态的,根据数据自行决定的<br>
                        创建列表使用[],执行切面默认是不包含最后一个的选择范围<br>
                        创建字典使用{"键名":值}这种构成方式<br>
                        布尔值True和False<br>
                        Python当中的缩进空格是有特殊含义的.<br>
                        通过def关键字可以定义函数<br>
                        Windows通过ctrl+Z+Enter退出解释器<br>
                    </p>
                </div>
            </section>
            <section id="1.4"><p class="section">1.4 Python脚本文件</p>
                <div>
                    <p>
                        python 文件路径+文件名就可以执行对应的python文件<br>
                        类通过class关键字来定义,默认构造函数方法名是__init__(self,...),只有在类的实例化初始化的时候调用一次.实例变量就是存储在各个实例当中的变量,可以通过self.xxx来访问<br>
                    </p>
                </div>
            </section>
            <section id="1.5"><p class="section">1.5 NumPy</p>
                <div>
                    <p>
                        通过Import numpy as np来把numpy计算库导入命名为np<br>
                        np.array()方法把Python列表作为参数生成Numpy数组numpy.ndarray.<br>
                        在数学上把一维数组称为向量,二维称为矩阵,三维即以上称为XX阶张量或者多维数组.<br>
                        形状不同数组之间的计算功能叫做广播.<br>
                        可以通过索引访问元素,例如x[0][1]表示第一行,第二列的元素.<br>
                        也可以使用数组来访问多个元素,例如x[np.array([0,2,4])获取索引为0,2,4的元素返回为一个np.array类型的数组对象.<br>
                    </p>
                </div>
            </section>
            <section id="1.6"><p class="section">1.6 Matplotlib</p>
                <div>
                    <p>
                        Matplotlib库是用来可视化的模块,使用Pyplot模块可以绘制图像,当中的image模块的Imread()方法可以读入图像.<br>
                    </p>
                </div>
            </section>
            <section id="1.7"><p class="section">1.7 小结</p>
                <div>
                    <p class="timeStamp" id="20240527">20240527-脉络梳理</p>
                    介绍了实现<strong>深度学习(神经网络)</strong>所需要的编程知识,为后面的学习做好准备<br>
                </div>
            </section>
        </article>
        <p class="timeStamp" id="20240625">20240625-感知机实现简单逻辑电路</p>

        <article id="2"><p class="chapter">2.感知机</p>
            <section id="2.1"><p class="section">2.1 感知机是什么</p>
                <div>
                    <strong>感知机</strong>是一种算法,由美国学者Frank Rosenblatt在1957年提出来的,是深度学习<strong>起源</strong>的算法<br>
                    <figure>
                        <img src="Resources/img/chapter2/001感知机.png" alt="感知机">
                        <p>
                            感知机接收多个信号,输出一个信号,只有两种值,传递信号(1),不传递信号(0)<br>
                            x1和x2是<strong>输入信号</strong><br>
                            w1和w2是<strong>权重</strong><br>
                            y是<strong>输出</strong>信号<br>
                            当x1w1+x2w2的总和<strong>超过</strong>某个<strong>阀值</strong>θ然后y才会<strong>输出1</strong><br>
                        </p>
                    </figure>
                </div>
            </section>
            <section id="2.2"><p class="section">2.2 简单逻辑电路</p>
                <figure>
                    <img src="Resources/img/chapter2/002真值表.png" alt="真值表">
                    <p>
                        目标:用感知机(w1,w2,θ)实现简单逻辑电路<br>
                        <strong>与门(And)</strong>:使用(0.5,0.5,0.8),只要w1,w2分别小于θ,之和大于θ即可<br>
                        <strong>或门(Or)</strong>:使用(0.5,0.5,0.4),只要w1,w2分别都大于θ即可<br>
                        <strong>非与门(No And)</strong>:使用(-0.5,-0.5,-0.8),w1,w2分别大于θ,加起来小于θ.<br>
                    </p>
                </figure>               
            </section>
            <section id="2.3"><p class="section">2.3 感知机的实现</p></section>
            <section id="2.4"><p class="section">2.4 感知机的局限性</p></section>
            <section id="2.5"><p class="section">2.5 多层感知机</p></section>
            <section id="2.6"><p class="section">2.6 从与非门到计算机</p></section>
            <section id="2.7"><p class="section">2.7 小结</p>
                <div>
                    学习了<strong>感知机</strong>-一种非常简单的算法.<br>
                    感知机是具有输入和输出的算法.(感觉这个描述像函数)<br>
                    感知机将权重和偏置设定为参数<br>
                    感知机可以表示与门和或门等逻辑电路,通过两层感知机可以表示异或门,通过多层感知机可以表示非线性空间.<br>
                </div>
            </section>
        </article>
        <article id="3"><p class="chapter">3.神经网络</p>
            <section id="3.1"><p class="section">3.1 从感知机到神经网络</p></section>
            <section id="3.2"><p class="section">3.2 激活函数</p></section>
            <section id="3.3"><p class="section">3.3 多维数组的运算</p></section>
            <section id="3.4"><p class="section">3.4 3层神经网络的实现</p></section>
            <section id="3.5"><p class="section">3.5 输出层的设计</p></section>
            <section id="3.6"><p class="section">3.6 手写数字识别</p></section>
            <section id="3.7"><p class="section">3.7 小结</p>
                <div>
                    介绍了神经网络的<strong>前向传播</strong>,感知机使用阶跃函数作为激活函数,神经网络使用sigmoid或ReLU函数.<br>
                    使用Numpy多维数组可以提高运算效率<br>
                    机器学习问题大体分为回归问题和分类问题,回归问题的激活函数使用恒等函数,分类问题使用softmax函数.<br>
                    分类问题中输出神经元的数量等于分类数.<br>
                    输入数据的集合称为合批.<br>
                </div>
            </section>
        </article>
        <article id="4"><p class="chapter">4.神经网络的学习</p>
            <section id="4.1"><p class="section">4.1 从数据中学习</p></section>
            <section id="4.2"><p class="section">4.2 损失函数</p></section>
            <section id="4.3"><p class="section">4.3 数值微分</p></section>
            <section id="4.4"><p class="section">4.4 梯度</p></section>
            <section id="4.5"><p class="section">4.5 学习算法的实现</p></section>
            <section id="4.6"><p class="section">4.6 小结</p>
                <div>
                    介绍了<strong>神经网络的学习</strong><br>
                    通过损失函数尽可能小的权重来达到目标.<br>
                    机器学习中的数据分为训练数据和测试数据,训练数据用来学习,测试数据用来评价.<br>
                    数值微分:给定微小值的擦还分求导的过程称为数值微分.利用数值微分可以计算权重参数的梯度.<br>
                </div>
            </section>
        </article>
        <article id="5"><p class="chapter">5.误差反向传播法</p>
            <section id="5.1"><p class="section">5.1 计算图</p></section>
            <section id="5.2"><p class="section">5.2 链式法则</p></section>
            <section id="5.3"><p class="section">5.3 反向传播</p></section>
            <section id="5.4"><p class="section">5.4 简单层的实现</p></section>
            <section id="5.5"><p class="section">5.5 激活函数层的实现</p></section>
            <section id="5.6"><p class="section">5.6 Affine/Softmax层的实现</p></section>
            <section id="5.7"><p class="section">5.7 误差反向传播法的实现</p></section>
            <section id="5.8"><p class="section">5.8 小结</p>
                <div>
                    介绍了将计算过程<strong>可视化的计算图</strong>,介绍了神经网络中的<strong>误差反向传播法</strong>,
                    通过将神经网络实现为层高效计算反向传播,通过比较数值微分和误差反向传播结果来判断是否构建正确.<br>
                </div>
            </section>
        </article>
        <article id="6"><p class="chapter">6.与学习相关的技巧</p>
            <section id="6.1"><p class="section">6.1 参数的更新</p></section>
            <section id="6.2"><p class="section">6.2 权重的初始值</p></section>
            <section id="6.3"><p class="section">6.3 Batch Normalization</p></section>
            <section id="6.4"><p class="section">6.4 正则化</p></section>
            <section id="6.5"><p class="section">6.5 超参数的验证</p></section>
            <section id="6.6"><p class="section">6.6 小结</p>
                <div>
                    学习神经网络中的一些重要技巧<strong>参数更新方法,权重初始化方法,批量正则化</strong><br>
                </div>
            </section>
        </article>
        <article id="7"><p class="chapter">7.卷积神经网络</p>
            <section id="7.1"><p class="section">7.1 整体结构</p></section>
            <section id="7.2"><p class="section">7.2 卷积层</p></section>
            <section id="7.3"><p class="section">7.3 池化层</p></section>
            <section id="7.4"><p class="section">7.4 卷积层和池化层的实现</p></section>
            <section id="7.5"><p class="section">7.5 CNN的实现</p></section>
            <section id="7.6"><p class="section">7.6 CNN的可视化</p></section>
            <section id="7.7"><p class="section">7.7 具有代表性的CNN</p></section>
            <section id="7.8"><p class="section">7.8 小结</p>
                <div>
                    介绍了<strong>CNN,增加了全基层和池化层</strong><br>
                </div>
            </section>
        </article>
        <article id="8"><p class="chapter">8.深度学习</p>
            <section id="8.1"><p class="section">8.1 加深网络</p></section>
            <section id="8.2"><p class="section">8.2 深度学习的小历史</p></section>
            <section id="8.3"><p class="section">8.3 深度学习的高速化</p></section>
            <section id="8.4"><p class="section">8.4 深度学习的应用案例</p></section>
            <section id="8.5"><p class="section">8.5 深度学习的未来</p></section>
            <section id="8.6"><p class="section">8.6 小结</p>
                <div>
                    实现了一个高级的CNN,手写数字识别精度提升.<br>
                </div>
            </section>
        </article>
        <article id="9"><p calss="chapter">9.附录和其他</p>
            <section id="9.1"><p class="section">9.1 特殊的学习思路</p>
                <p>
                 <p class="timeStamp" id="20240524">20240524-万物初开</p>
                    计划这一本书籍采用独特的树状学习法<br>
                    1.所有一级二级目录确认整体结构,同时构建XML的结构(20240524-20240524完成)<br>
                    2.对每一大章的小结细看<br>
                    3.对每一个二级目录速度然后一句话概括<br>
                    4.对每个章节进行精读<br>
                    5.建立第二个压缩总结的Xmind,归纳(写到这个章节)<br>
                    6.构建一个故事来描述整本书(写到这个章节)<br>
                </p>
            </section>  
            <section id="9.2"><p class="section">9.2 Softmax-with-Loss层的计算图</p></section>
        </article>
        <footer><a href="../../../../index.html">首页</a></footer>
        <script>
                // 读取存储的滚动位置并滚动到该位置  
            const scrollPositionKey = 'scrollPosition';  // 定义滚动位置变量
            const storedScrollPosition = localStorage.getItem(scrollPositionKey); // localStorage是存在用户设备上
            
            window.onload = function()  // 读取窗口的时候就回滚到上次位置
            {
                if (storedScrollPosition)  // 如果滚动位置存在 
                {  
                    window.scrollTo(0, parseInt(storedScrollPosition)); // 滚动到这个位置 
                } 
            } 
            
            // 监听滚动事件并存储位置  
            window.addEventListener('scroll', () => 
            {  
                const scrollPosition = window.scrollY || window.pageYOffset || document.body.scrollTop + (document.documentElement && document.documentElement.scrollTop || 0);  
                localStorage.setItem(scrollPositionKey, scrollPosition);  
            });
        </script>
    </body>
</html>